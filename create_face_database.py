import cv2
import numpy as np
import torch
import os
from facenet_pytorch import MTCNN, InceptionResnetV1

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• MTCNN ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡πÅ‡∏•‡∏∞ FaceNet ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Embedding
mtcnn = MTCNN(image_size=160, margin=40, min_face_size=20)
facenet = InceptionResnetV1(pretrained='vggface2').eval()

# ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
dataset_path = r"C:\Users\Sujitra 582\Desktop\CPE495-Project\Face-Recognition-Attendance-System\faces_dataset"
if not os.path.exists(dataset_path):
    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå '{dataset_path}' ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
    exit()

face_embeddings = {}

# ‡∏≠‡πà‡∏≤‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
for person_name in os.listdir(dataset_path):
    person_folder = os.path.join(dataset_path, person_name)
    
    if os.path.isdir(person_folder):  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
        embeddings_list = []
        for filename in os.listdir(person_folder):
            if filename.endswith(".jpg") or filename.endswith(".png"):
                image_path = os.path.join(person_folder, filename)

                # ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û
                img = cv2.imread(image_path)
                if img is None:
                    print(f"‚ö†Ô∏è ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {image_path}")
                    continue
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞ Crop
                face = mtcnn(img_rgb)
                
                if face is not None:
                    img_tensor = face.unsqueeze(0)  # ‡πÄ‡∏û‡∏¥‡πà‡∏° Batch Dimension
                    
                    # ‡∏î‡∏∂‡∏á Face Embedding
                    with torch.no_grad():
                        embedding = facenet(img_tensor).numpy().flatten()
                        embeddings_list.append(embedding)

                    print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: {person_name}, ‡∏£‡∏π‡∏õ: {filename}")
                else:
                    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û: {image_path}")

        # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á embeddings ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if embeddings_list:
            face_embeddings[person_name] = np.mean(embeddings_list, axis=0)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå .npy
np.save("face_database.npy", face_embeddings)
print("üìÇ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", len(face_embeddings), "‡∏Ñ‡∏ô")