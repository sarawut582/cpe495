import cv2
import numpy as np
import os
import torch
from facenet_pytorch import MTCNN, InceptionResnetV1
import mediapipe as mp
import json
import requests
from datetime import datetime

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• FaceNet ‡πÅ‡∏•‡∏∞ MTCNN
facenet_model = InceptionResnetV1(pretrained='vggface2').eval()
mtcnn = MTCNN(image_size=160, margin=60, min_face_size=20)
mp_face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True)

# ‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå npy
face_database_path = r"C:\Users\Sujitra 582\Desktop\CPE495-Project\Face-Recognition-Attendance-System\face_database.npy"
if os.path.exists(face_database_path):
    data = np.load(face_database_path, allow_pickle=True).item()
    print(f"‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {face_database_path}")
    
    if isinstance(data, dict):
        face_embeddings = data
        print(f"‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(face_embeddings)} ‡∏Ñ‡∏ô")
    else:
        print("‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô face_database.npy ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà dictionary!")
        exit()
else:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå face_database.npy!")
    exit()

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á face embedding
def recognize_face_with_mtcnn(face_resized):
    try:
        if face_resized is None or face_resized.size == 0:
            return None
        face_resized = cv2.resize(face_resized, (160, 160))
        face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)
        face_tensor = torch.tensor(face_rgb, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0) / 255.0
        with torch.no_grad():
            embedding = facenet_model(face_tensor)
        return embedding.squeeze().numpy()
    except Exception as e:
        print("‚ö†Ô∏è Error in face embedding:", e)
        return None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á (cosine similarity)
def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

# URL ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå API
server_url = "http://172.20.10.2:5000/api/student-checks"

# ‡πÇ‡∏´‡∏•‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
video_path = r"C:\Users\Sujitra 582\Desktop\CPE495-Project\Face-Recognition-Attendance-System\video\IMG_9279.MOV"
cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    print("\n‚ùå Error: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÑ‡∏î‡πâ!")
    exit()

# ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
output_folder = "detected_faces"
os.makedirs(output_folder, exist_ok=True)

frame_count = 0
saved_faces = set()

# ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏à‡∏≤‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame_resized = cv2.resize(frame, (640, 480))
    frame_resized = cv2.transpose(frame_resized)
    frame_resized = cv2.flip(frame_resized, flipCode=1)

    boxes, _ = mtcnn.detect(frame_resized)
    if boxes is not None:
        for i, box in enumerate(boxes):
            x1, y1, x2, y2 = map(int, box)
            x1, y1, x2, y2 = max(0, x1), max(0, y1), min(frame_resized.shape[1], x2), min(frame_resized.shape[0], y2)
            face = frame_resized[y1:y2, x1:x2]

            if face.size == 0:
                continue

            if (x1, y1, x2, y2) not in saved_faces:
                face_filename = os.path.join(output_folder, f"face_{frame_count:04d}.jpg")
                cv2.imwrite(face_filename, face)
                saved_faces.add((x1, y1, x2, y2))
                frame_count += 1
                cv2.rectangle(frame_resized, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame_resized, "Face Detected", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

    cv2.imshow("Video - Face Detection", frame_resized)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

# üîç ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")

existing_names = set()
attendance_records = []

for face_file in os.listdir(output_folder):
    face_path = os.path.join(output_folder, face_file)
    face_img = cv2.imread(face_path)
    face_embedding = recognize_face_with_mtcnn(face_img)

    if face_embedding is not None:
        name = "Unknown"
        best_similarity = float("-inf")

        for db_name, db_embedding in face_embeddings.items():
            similarity = cosine_similarity(face_embedding, db_embedding)
            if similarity > best_similarity:
                best_similarity = similarity
                name = db_name

        if best_similarity >= 0.8 and name != "Unknown" and name not in existing_names:
            print(f"üìå ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô {face_file} ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö {name} (‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ {best_similarity:.2f})")
            
            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏ß‡∏•‡∏≤ Check_Date ‡πÅ‡∏•‡∏∞ Check_Time
            current_time = datetime.now()
            attendance_data = {
                "Student_ID": int(name),  # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (int)
                "Course_ID": "CPE451",
                "Check_Date": current_time.isoformat(),  # ‡∏™‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô DateTime ‡∏à‡∏£‡∏¥‡∏á ‡πÜ
                "Check_Time": current_time.strftime("%H:%M:%S"),  # ‡∏™‡πà‡∏á‡πÅ‡∏Ñ‡πà‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô
                "Check_Status": "Absent"  # ‡πÄ‡∏û‡∏¥‡πà‡∏° Check_Status
            }
            attendance_records.append(attendance_data)

            # ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
            try:
                headers = {"Content-Type": "application/json"}
                response = requests.post(server_url, json=attendance_data, headers=headers)
                if response.status_code == 200:
                    print(f"‚úÖ Successfully sent data for {name}")
                else:
                    print(f"‚ùå Failed to send data for {name}, Status Code: {response.status_code}, Response: {response.text}")
            except Exception as e:
                print(f"‚ö†Ô∏è Error sending data: {e}")
            
            existing_names.add(name)

    # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
    os.remove(face_path)
    print(f"‚ùå ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå: {face_file}")

print("‚úÖ ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON
json_output_path = "face_recognition_results.json"
with open(json_output_path, 'w', encoding='utf-8') as json_file:
    json.dump(attendance_records, json_file, ensure_ascii=False, indent=4)

print(f"‚úÖ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå: {json_output_path}")
